{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EAGAgAxzUK2x",
        "outputId": "5ba3c110-9483-48ad-82d5-a92619fb1cdb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\USMM TEJA\\AppData\\Roaming\\Python\\Python312\\site-packages\\ultralytics\\nn\\tasks.py:781: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  ckpt = torch.load(file, map_location=\"cpu\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Found https://ultralytics.com/images/bus.jpg locally at bus.jpg\n",
            "image 1/1 c:\\Users\\USMM TEJA\\Desktop\\IITH\\7th Sem\\YOLOV8\\bus.jpg: 320x256 3 persons, 1 bus, 45.2ms\n",
            "Speed: 0.0ms preprocess, 45.2ms inference, 1.2ms postprocess per image at shape (1, 3, 320, 256)\n",
            "Results saved to \u001b[1mc:\\Users\\USMM TEJA\\Desktop\\IITH\\7th Sem\\YOLOV8\\ultralytics\\runs\\detect\\predict\u001b[0m\n",
            "Width of Box: 185.3315887451172, Height of Box: 509.1540832519531\n",
            "Width of Box: 793.9190063476562, Height of Box: 525.06396484375\n",
            "Width of Box: 127.81626892089844, Height of Box: 451.54010009765625\n",
            "Width of Box: 139.20477294921875, Height of Box: 493.9075012207031\n"
          ]
        }
      ],
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Load a pre-trained YOLOv8 model\n",
        "model = YOLO(\"yolov8n.pt\")\n",
        "\n",
        "# Specify the source image\n",
        "source = \"https://ultralytics.com/images/bus.jpg\"\n",
        "\n",
        "# Make predictions\n",
        "results = model.predict(source, save=True, imgsz=320, conf=0.5)\n",
        "\n",
        "# Extract bounding box dimensions\n",
        "boxes = results[0].boxes.xywh.cpu()\n",
        "for box in boxes:\n",
        "    x, y, w, h = box\n",
        "    print(f\"Width of Box: {w}, Height of Box: {h}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name: ultralytics\n",
            "Version: 8.2.60\n",
            "Summary: Ultralytics YOLOv8 for SOTA object detection, multi-object tracking, instance segmentation, pose estimation and image classification.\n",
            "Home-page: \n",
            "Author: Glenn Jocher, Ayush Chaurasia, Jing Qiu\n",
            "Author-email: \n",
            "License: AGPL-3.0\n",
            "Location: C:\\Users\\USMM TEJA\\AppData\\Roaming\\Python\\Python312\\site-packages\n",
            "Requires: matplotlib, numpy, opencv-python, pandas, pillow, psutil, py-cpuinfo, pyyaml, requests, scipy, seaborn, torch, torchvision, tqdm, ultralytics-thop\n",
            "Required-by: \n"
          ]
        }
      ],
      "source": [
        "!pip show ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "c:\\Users\\USMM TEJA\\Desktop\\IITH\\7th Sem\\YOLOV8\n"
          ]
        }
      ],
      "source": [
        "!cd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yq1O5YBpVPmF",
        "outputId": "63959195-3a7e-4fe8-cdd6-8f6ea1b534ff"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100   910  100   910    0     0   2148      0 --:--:-- --:--:-- --:--:--  2156\n",
            "100   910  100   910    0     0   2147      0 --:--:-- --:--:-- --:--:--  2156\n",
            "\n",
            "  0     0    0     0    0     0      0      0 --:--:--  0:00:01 --:--:--     0\n",
            "  0 66.9M    0 17647    0     0   7409      0  2:37:53  0:00:02  2:37:51 20615\n",
            "  0 66.9M    0  223k    0     0  68578      0  0:17:03  0:00:03  0:17:00  123k\n",
            "  4 66.9M    4 3280k    0     0   755k      0  0:01:30  0:00:04  0:01:26 1165k\n",
            " 21 66.9M   21 14.3M    0     0  2753k      0  0:00:24  0:00:05  0:00:19 3854k\n",
            " 38 66.9M   38 25.4M    0     0  4114k      0  0:00:16  0:00:06  0:00:10 5418k\n",
            " 54 66.9M   54 36.7M    0     0  5121k      0  0:00:13  0:00:07  0:00:06 7576k\n",
            " 71 66.9M   71 47.8M    0     0  5879k      0  0:00:11  0:00:08  0:00:03 9764k\n",
            " 85 66.9M   85 57.5M    0     0  6310k      0  0:00:10  0:00:09  0:00:01 10.8M\n",
            "100 66.9M  100 66.9M    0     0  6739k      0  0:00:10  0:00:10 --:--:-- 10.8M\n"
          ]
        }
      ],
      "source": [
        "# https://public.roboflow.com/ds/5EYxQJiUTb?key=Lr1mQYl8CA\n",
        "!curl -L \"https://public.roboflow.com/ds/5EYxQJiUTb?key=Lr1mQYl8CA\" -o roboflow.zip\n",
        "!tar -xf roboflow.zip\n",
        "!del roboflow.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HsnSskpsV8V9",
        "outputId": "6f11fd18-d8d9-4be2-97e8-b9ffdcbfd61f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "c:\\Users\\USMM TEJA\\Desktop\\IITH\\7th Sem\\YOLOV8\n"
          ]
        }
      ],
      "source": [
        "!cd \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-_MNO6kGaAo7",
        "outputId": "f4303783-8cc9-4dab-8f9f-47948569b93d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train: ../train/images\n",
            "val: ../valid/images\n",
            "\n",
            "nc: 7\n",
            "names: ['fish', 'jellyfish', 'penguin', 'puffin', 'shark', 'starfish', 'stingray']\n"
          ]
        }
      ],
      "source": [
        "!type data.yaml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "    Arguments received: ['yolo', 'help']. Ultralytics 'yolo' commands use the following syntax:\n",
            "\n",
            "        yolo TASK MODE ARGS\n",
            "\n",
            "        Where   TASK (optional) is one of {'classify', 'segment', 'obb', 'pose', 'detect'}\n",
            "                MODE (required) is one of {'export', 'predict', 'track', 'benchmark', 'train', 'val'}\n",
            "                ARGS (optional) are any number of custom 'arg=value' pairs like 'imgsz=320' that override defaults.\n",
            "                    See all ARGS at https://docs.ultralytics.com/usage/cfg or with 'yolo cfg'\n",
            "\n",
            "    1. Train a detection model for 10 epochs with an initial learning_rate of 0.01\n",
            "        yolo train data=coco8.yaml model=yolov8n.pt epochs=10 lr0=0.01\n",
            "\n",
            "    2. Predict a YouTube video using a pretrained segmentation model at image size 320:\n",
            "        yolo predict model=yolov8n-seg.pt source='https://youtu.be/LNwODJXcvt4' imgsz=320\n",
            "\n",
            "    3. Val a pretrained detection model at batch-size 1 and image size 640:\n",
            "        yolo val model=yolov8n.pt data=coco8.yaml batch=1 imgsz=640\n",
            "\n",
            "    4. Export a YOLOv8n classification model to ONNX format at image size 224 by 128 (no TASK required)\n",
            "        yolo export model=yolov8n-cls.pt format=onnx imgsz=224,128\n",
            "\n",
            "    5. Explore your datasets using semantic search and SQL with a simple GUI powered by Ultralytics Explorer API\n",
            "        yolo explorer\n",
            "    \n",
            "    6. Streamlit real-time object detection on your webcam with Ultralytics YOLOv8\n",
            "        yolo streamlit-predict\n",
            "        \n",
            "    7. Run special commands:\n",
            "        yolo help\n",
            "        yolo checks\n",
            "        yolo version\n",
            "        yolo settings\n",
            "        yolo copy-cfg\n",
            "        yolo cfg\n",
            "\n",
            "    Docs: https://docs.ultralytics.com\n",
            "    Community: https://community.ultralytics.com\n",
            "    GitHub: https://github.com/ultralytics/ultralytics\n",
            "    \n"
          ]
        }
      ],
      "source": [
        "!yolo help"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!cd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fHXHWX18ZP1g",
        "outputId": "5f5f6acc-6337-414b-d977-5f0dea66a4c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "New https://pypi.org/project/ultralytics/8.2.79 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
            "Ultralytics YOLOv8.2.60 ðŸš€ Python-3.12.5 torch-2.4.0+cpu CPU (11th Gen Intel Core(TM) i5-1135G7 2.40GHz)\n",
            "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=data.yaml, epochs=1, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=c:\\Users\\USMM TEJA\\Desktop\\IITH\\7th Sem\\YOLOV8\\ultralytics\\runs\\detect\\train\n",
            "Overriding model.yaml nc=80 with nc=7\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    752677  ultralytics.nn.modules.head.Detect           [7, [64, 128, 256]]           \n",
            "Model summary: 225 layers, 3,012,213 parameters, 3,012,197 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 319/355 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: C:\\Users\\USMM TEJA\\Desktop\\IITH\\7th Sem\\YOLOV8\\train\\labels.cache\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: C:\\Users\\USMM TEJA\\Desktop\\IITH\\7th Sem\\YOLOV8\\valid\\labels.cache\n",
            "Plotting labels to c:\\Users\\USMM TEJA\\Desktop\\IITH\\7th Sem\\YOLOV8\\ultralytics\\runs\\detect\\train\\labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000909, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 0 dataloader workers\n",
            "Logging results to \u001b[1mc:\\Users\\USMM TEJA\\Desktop\\IITH\\7th Sem\\YOLOV8\\ultralytics\\runs\\detect\\train\u001b[0m\n",
            "Starting training for 1 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "                   all        127        909     0.0146      0.527      0.104     0.0573\n",
            "\n",
            "1 epochs completed in 0.106 hours.\n",
            "Optimizer stripped from c:\\Users\\USMM TEJA\\Desktop\\IITH\\7th Sem\\YOLOV8\\ultralytics\\runs\\detect\\train\\weights\\last.pt, 6.2MB\n",
            "Optimizer stripped from c:\\Users\\USMM TEJA\\Desktop\\IITH\\7th Sem\\YOLOV8\\ultralytics\\runs\\detect\\train\\weights\\best.pt, 6.2MB\n",
            "\n",
            "Validating c:\\Users\\USMM TEJA\\Desktop\\IITH\\7th Sem\\YOLOV8\\ultralytics\\runs\\detect\\train\\weights\\best.pt...\n",
            "Ultralytics YOLOv8.2.60 ðŸš€ Python-3.12.5 torch-2.4.0+cpu CPU (11th Gen Intel Core(TM) i5-1135G7 2.40GHz)\n",
            "Model summary (fused): 168 layers, 3,007,013 parameters, 0 gradients, 8.1 GFLOPs\n",
            "                   all        127        909     0.0143      0.525      0.104     0.0572\n",
            "                  fish         63        459     0.0593      0.527      0.202     0.0948\n",
            "             jellyfish          9        155     0.0105      0.561      0.197      0.116\n",
            "               penguin         17        104    0.00491      0.279     0.0182    0.00863\n",
            "                puffin         15         74    0.00264       0.23    0.00879     0.0038\n",
            "                 shark         28         57     0.0153      0.754      0.149     0.0709\n",
            "              starfish         17         27     0.0039       0.63     0.0658     0.0538\n",
            "              stingray         23         33    0.00369      0.697     0.0843     0.0529\n",
            "Speed: 5.3ms preprocess, 189.7ms inference, 0.0ms loss, 5.9ms postprocess per image\n",
            "Results saved to \u001b[1mc:\\Users\\USMM TEJA\\Desktop\\IITH\\7th Sem\\YOLOV8\\ultralytics\\runs\\detect\\train\u001b[0m\n",
            "ðŸ’¡ Learn more at https://docs.ultralytics.com/modes/train\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\USMM TEJA\\AppData\\Roaming\\Python\\Python312\\site-packages\\ultralytics\\nn\\tasks.py:781: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  ckpt = torch.load(file, map_location=\"cpu\")\n",
            "C:\\Users\\USMM TEJA\\AppData\\Roaming\\Python\\Python312\\site-packages\\ultralytics\\engine\\trainer.py:267: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = torch.cuda.amp.GradScaler(enabled=self.amp)\n",
            "\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\USMM TEJA\\Desktop\\IITH\\7th Sem\\YOLOV8\\train\\labels...:   0%|          | 0/448 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\USMM TEJA\\Desktop\\IITH\\7th Sem\\YOLOV8\\train\\labels... 43 images, 0 backgrounds, 0 corrupt:  10%|â–‰         | 43/448 [00:00<00:01, 382.47it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\USMM TEJA\\Desktop\\IITH\\7th Sem\\YOLOV8\\train\\labels... 94 images, 0 backgrounds, 0 corrupt:  21%|â–ˆâ–ˆ        | 94/448 [00:00<00:00, 445.36it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\USMM TEJA\\Desktop\\IITH\\7th Sem\\YOLOV8\\train\\labels... 143 images, 0 backgrounds, 0 corrupt:  32%|â–ˆâ–ˆâ–ˆâ–      | 143/448 [00:00<00:00, 459.41it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\USMM TEJA\\Desktop\\IITH\\7th Sem\\YOLOV8\\train\\labels... 199 images, 0 backgrounds, 0 corrupt:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 199/448 [00:00<00:00, 493.70it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\USMM TEJA\\Desktop\\IITH\\7th Sem\\YOLOV8\\train\\labels... 254 images, 0 backgrounds, 0 corrupt:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 254/448 [00:00<00:00, 499.30it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\USMM TEJA\\Desktop\\IITH\\7th Sem\\YOLOV8\\train\\labels... 305 images, 1 backgrounds, 0 corrupt:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 305/448 [00:00<00:00, 502.53it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\USMM TEJA\\Desktop\\IITH\\7th Sem\\YOLOV8\\train\\labels... 366 images, 1 backgrounds, 0 corrupt:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 366/448 [00:00<00:00, 512.31it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\USMM TEJA\\Desktop\\IITH\\7th Sem\\YOLOV8\\train\\labels... 423 images, 1 backgrounds, 0 corrupt:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 423/448 [00:00<00:00, 524.84it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\USMM TEJA\\Desktop\\IITH\\7th Sem\\YOLOV8\\train\\labels... 448 images, 1 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 448/448 [00:00<00:00, 501.02it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\USMM TEJA\\Desktop\\IITH\\7th Sem\\YOLOV8\\valid\\labels...:   0%|          | 0/127 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\USMM TEJA\\Desktop\\IITH\\7th Sem\\YOLOV8\\valid\\labels... 50 images, 0 backgrounds, 0 corrupt:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 50/127 [00:00<00:00, 485.56it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\USMM TEJA\\Desktop\\IITH\\7th Sem\\YOLOV8\\valid\\labels... 103 images, 0 backgrounds, 0 corrupt:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 103/127 [00:00<00:00, 503.59it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\USMM TEJA\\Desktop\\IITH\\7th Sem\\YOLOV8\\valid\\labels... 127 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 127/127 [00:00<00:00, 503.15it/s]\n",
            "\n",
            "  0%|          | 0/28 [00:00<?, ?it/s]\n",
            "        1/1         0G      1.341      4.222      1.285        177        640:   0%|          | 0/28 [00:19<?, ?it/s]\n",
            "        1/1         0G      1.341      4.222      1.285        177        640:   4%|â–Ž         | 1/28 [00:19<08:45, 19.47s/it]\n",
            "        1/1         0G       1.41      4.254      1.301        292        640:   4%|â–Ž         | 1/28 [00:30<08:45, 19.47s/it]\n",
            "        1/1         0G       1.41      4.254      1.301        292        640:   7%|â–‹         | 2/28 [00:30<06:09, 14.22s/it]\n",
            "        1/1         0G      1.411      4.214      1.325        188        640:   7%|â–‹         | 2/28 [00:40<06:09, 14.22s/it]\n",
            "        1/1         0G      1.411      4.214      1.325        188        640:  11%|â–ˆ         | 3/28 [00:40<05:09, 12.36s/it]\n",
            "        1/1         0G      1.387      4.232      1.322        159        640:  11%|â–ˆ         | 3/28 [00:50<05:09, 12.36s/it]\n",
            "        1/1         0G      1.387      4.232      1.322        159        640:  14%|â–ˆâ–        | 4/28 [00:50<04:38, 11.61s/it]\n",
            "        1/1         0G      1.451      4.257      1.341        185        640:  14%|â–ˆâ–        | 4/28 [01:00<04:38, 11.61s/it]\n",
            "        1/1         0G      1.451      4.257      1.341        185        640:  18%|â–ˆâ–Š        | 5/28 [01:00<04:12, 10.96s/it]\n",
            "        1/1         0G      1.476      4.262      1.333        159        640:  18%|â–ˆâ–Š        | 5/28 [01:10<04:12, 10.96s/it]\n",
            "        1/1         0G      1.476      4.262      1.333        159        640:  21%|â–ˆâ–ˆâ–       | 6/28 [01:10<03:54, 10.65s/it]\n",
            "        1/1         0G      1.495      4.262      1.333        183        640:  21%|â–ˆâ–ˆâ–       | 6/28 [01:20<03:54, 10.65s/it]\n",
            "        1/1         0G      1.495      4.262      1.333        183        640:  25%|â–ˆâ–ˆâ–Œ       | 7/28 [01:20<03:39, 10.48s/it]\n",
            "        1/1         0G       1.51      4.252      1.325        263        640:  25%|â–ˆâ–ˆâ–Œ       | 7/28 [01:30<03:39, 10.48s/it]\n",
            "        1/1         0G       1.51      4.252      1.325        263        640:  29%|â–ˆâ–ˆâ–Š       | 8/28 [01:30<03:25, 10.29s/it]\n",
            "        1/1         0G      1.519      4.243      1.321        267        640:  29%|â–ˆâ–ˆâ–Š       | 8/28 [01:40<03:25, 10.29s/it]\n",
            "        1/1         0G      1.519      4.243      1.321        267        640:  32%|â–ˆâ–ˆâ–ˆâ–      | 9/28 [01:40<03:16, 10.33s/it]\n",
            "        1/1         0G      1.516      4.225      1.314        150        640:  32%|â–ˆâ–ˆâ–ˆâ–      | 9/28 [01:51<03:16, 10.33s/it]\n",
            "        1/1         0G      1.516      4.225      1.314        150        640:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 10/28 [01:51<03:06, 10.38s/it]\n",
            "        1/1         0G       1.51      4.199      1.312        177        640:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 10/28 [02:01<03:06, 10.38s/it]\n",
            "        1/1         0G       1.51      4.199      1.312        177        640:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 11/28 [02:01<02:53, 10.22s/it]\n",
            "        1/1         0G      1.508      4.176      1.306        185        640:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 11/28 [02:11<02:53, 10.22s/it]\n",
            "        1/1         0G      1.508      4.176      1.306        185        640:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 12/28 [02:11<02:43, 10.22s/it]\n",
            "        1/1         0G      1.518       4.16      1.307        212        640:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 12/28 [02:24<02:43, 10.22s/it]\n",
            "        1/1         0G      1.518       4.16      1.307        212        640:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 13/28 [02:24<02:46, 11.11s/it]\n",
            "        1/1         0G      1.512      4.139      1.302        137        640:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 13/28 [02:39<02:46, 11.11s/it]\n",
            "        1/1         0G      1.512      4.139      1.302        137        640:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 14/28 [02:39<02:52, 12.34s/it]\n",
            "        1/1         0G      1.515      4.121      1.298        263        640:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 14/28 [02:54<02:52, 12.34s/it]\n",
            "        1/1         0G      1.515      4.121      1.298        263        640:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 15/28 [02:54<02:51, 13.19s/it]\n",
            "        1/1         0G      1.518        4.1      1.296        243        640:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 15/28 [03:10<02:51, 13.19s/it]\n",
            "        1/1         0G      1.518        4.1      1.296        243        640:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 16/28 [03:10<02:47, 13.99s/it]\n",
            "        1/1         0G      1.517      4.079       1.29        170        640:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 16/28 [03:24<02:47, 13.99s/it]\n",
            "        1/1         0G      1.517      4.079       1.29        170        640:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 17/28 [03:24<02:34, 14.03s/it]\n",
            "        1/1         0G      1.504      4.034      1.281        154        640:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 17/28 [03:34<02:34, 14.03s/it]\n",
            "        1/1         0G      1.504      4.034      1.281        154        640:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 18/28 [03:34<02:07, 12.75s/it]\n",
            "        1/1         0G      1.507      4.012      1.279        258        640:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 18/28 [03:44<02:07, 12.75s/it]\n",
            "        1/1         0G      1.507      4.012      1.279        258        640:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 19/28 [03:44<01:46, 11.84s/it]\n",
            "        1/1         0G      1.512      3.986      1.276        182        640:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 19/28 [03:54<01:46, 11.84s/it]\n",
            "        1/1         0G      1.512      3.986      1.276        182        640:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 20/28 [03:54<01:30, 11.30s/it]\n",
            "        1/1         0G      1.515      3.961      1.272        282        640:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 20/28 [04:06<01:30, 11.30s/it]\n",
            "        1/1         0G      1.515      3.961      1.272        282        640:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 21/28 [04:06<01:20, 11.50s/it]\n",
            "        1/1         0G      1.519      3.937      1.269        220        640:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 21/28 [04:20<01:20, 11.50s/it]\n",
            "        1/1         0G      1.519      3.937      1.269        220        640:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 22/28 [04:20<01:12, 12.13s/it]\n",
            "        1/1         0G      1.531      3.921      1.268        266        640:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 22/28 [04:33<01:12, 12.13s/it]\n",
            "        1/1         0G      1.531      3.921      1.268        266        640:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 23/28 [04:33<01:02, 12.55s/it]\n",
            "        1/1         0G      1.534      3.899      1.265        183        640:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 23/28 [04:46<01:02, 12.55s/it]\n",
            "        1/1         0G      1.534      3.899      1.265        183        640:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 24/28 [04:46<00:50, 12.66s/it]\n",
            "        1/1         0G      1.544      3.879      1.267        277        640:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 24/28 [05:00<00:50, 12.66s/it]\n",
            "        1/1         0G      1.544      3.879      1.267        277        640:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 25/28 [05:00<00:39, 13.13s/it]\n",
            "        1/1         0G      1.548      3.845      1.266        228        640:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 25/28 [05:13<00:39, 13.13s/it]\n",
            "        1/1         0G      1.548      3.845      1.266        228        640:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 26/28 [05:13<00:26, 13.05s/it]\n",
            "        1/1         0G      1.554       3.82      1.266        208        640:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 26/28 [05:26<00:26, 13.05s/it]\n",
            "        1/1         0G      1.554       3.82      1.266        208        640:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 27/28 [05:26<00:13, 13.07s/it]\n",
            "        1/1         0G      1.556      3.797      1.266        167        640:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 27/28 [05:39<00:13, 13.07s/it]\n",
            "        1/1         0G      1.556      3.797      1.266        167        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [05:39<00:00, 12.87s/it]\n",
            "        1/1         0G      1.556      3.797      1.266        167        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [05:39<00:00, 12.11s/it]\n",
            "\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/4 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:10<00:32, 10.91s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:20<00:19,  9.88s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:29<00:09,  9.77s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:38<00:00,  9.52s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:38<00:00,  9.71s/it]\n",
            "\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/4 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:08<00:25,  8.44s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:14<00:14,  7.09s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:20<00:06,  6.70s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:27<00:00,  6.74s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:27<00:00,  6.90s/it]\n"
          ]
        }
      ],
      "source": [
        "# !yolo train model=yolov8n.pt data=data.yaml epochs=1 imgsz=800\n",
        "!yolo train data=data.yaml model=yolov8n.pt epochs=1 lr0=0.01"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 809
        },
        "id": "VqW8uzkNu9Me",
        "outputId": "c809ebab-2cbe-438b-adc2-0f1eb662a9c3"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Image, display\n",
        "display(Image(filename='/content/ultralytics/runs/detect/train/confusion_matrix.png'))\n",
        "# Image(filename='/content/ultralytics/runs/detect/train/confusion_matrix.png', width=600)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29umxvyEv5xs",
        "outputId": "e712b2bb-2cc9-44f2-e50e-03e7ea7a5223"
      },
      "outputs": [],
      "source": [
        "!yolo task=detect mode=predict model=/content/ultralytics/runs/detect/train/weights/best.pt conf=0.25 source=/content/test/images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "e86usITaw86U",
        "outputId": "2be6e173-8a48-4707-fde7-528216c69f98"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "\n",
        "for imageName in glob.glob('/content/ultralytics/runs/detect/predict2/*.jpg'):\n",
        "  display(Image(filename = imageName))\n",
        "  print('\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m7iBSzeryeKn"
      },
      "outputs": [],
      "source": [
        "model = YOLO('/content/ultralytics/runs/detect/train/weights/best.pt')\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
